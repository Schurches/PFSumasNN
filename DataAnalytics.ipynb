{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentación del Modelo 1: Red Neuronal Artificial.\n",
    "\n",
    "### Descripción\n",
    "\n",
    "Inicialmente se pensó por utilizar un Supporting Vector Machine para predecir. Sin embargo, tras haber hecho pruebas no tuvo mucha presición al momento de clasificar, por lo que se optó por una red neuronal. Con la Red Neuronal Artificial lo que se busca es que cuando un nuevo jugador entre al juego, se pueda estimadar cuál sería la intensidad de ejercicios para cada nivel de dificultad en la primera sesión de juego. Esta intensidad se irá re-ajustando con base en el desempeño que los usuarios tengan al contestar los grupos de ejercicios que se le presenten en las futuras sesiones de juego. Sin embargo, la funcionalidad recientemente descrita será destinada para el modelo 2. Este modelo se encargará solo de los nuevos jugadores.\n",
    "\n",
    "### Librerías\n",
    "\n",
    "* __NumPy__: Para operaciones algebráicas y arreglos multidimensionales\n",
    "* __Pandas__: Para estructuras de datos fáciles de usar, con alto desempeño y varias utilidades de analítica de datos\n",
    "* __Seaborn__: Para visualizaciones de datos estadísticos con interfaz profesional.\n",
    "* __Scikit-Learn__: Para realizar preprocesamiento y partición de datos, utilizar SVM y validar la precisión de los modelos de ML.\n",
    "* __Keras__: Para utilizar redes neuronales de una forma rápida, sin complicaciones.\n",
    "* __Pickle__: Para serializar objetos. Se usará para guardar los datos que describen a la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing;\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#Keras library\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.externals import joblib \n",
    "#Serialization\n",
    "import pickle;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estructura del dataset\n",
    "\n",
    "Los datos ya han sido previamente limpiados y están listos para usar. Se cargarán un total de 15500 datos, provenientes de 5 colegios. Los datos están distribuídos de la siguiente forma:\n",
    "\n",
    "* __Colegio Hartfort__: 2875 datos provenientes de 115 niños (Grados 1-5) (M,F)\n",
    "* __Colegio La Enseñanza__: 2800 datos provenientes de 112 niños (Grados 1-5) (F)\n",
    "* __Colegio del Sagrado Corazón__: 1650 datos provenientes de 66 niños (robots) (Grados 1-5) (M,F)\n",
    "* __Colegio Marco Fidel Suarez__: 3525 datos provenientes de 141 niños (Grados 1,2,4,5) (M,F)\n",
    "* __Colegio Marie Paussepin__: 4650 datos provenientes de 186 niños (Grados 1-5) (F)\n",
    "\n",
    "Donde \n",
    "* __M__: Significa Masculino\n",
    "* __F__: Significa Femenino\n",
    "\n",
    "Los datos serán cargados de los diferentes archivos .csv, que ya han pasado por un proceso de transformación y limpieza, por lo que no se encontrarán datos incompletos o erróneos o basura. La estructura de las tablas será la siguiente:\n",
    "\n",
    "* __Edad__: La edad del niño\n",
    "* __Escuela__: El nombre del colegio del niño\n",
    "* __Género__: Género del niño, donde 0 es hombre y 1 es mujer.\n",
    "* __Grado__: El grado que cursa actualmente (1-5)\n",
    "* __LoID__: ID del objetivo de aprendizaje (0 a 4) asociado al ejercicio que contestó\n",
    "* __Problema__: El ejercicio en concreto que resolvió\n",
    "* __Tiempo__: El tiempo que tardó en contestar dicho ejercicio\n",
    "* __userID__: El ID único de cada jugador (Dado por firebase)\n",
    "* __isCorrect__: Integer que determina si el ejercicio lo contestó correctamente. 0 es si se equivocó y 1 es si lo contestó bien. Cabe destacar que cuando el niño contesta \"no sé\" o se equivoca, ambos son categorizados como un 0 (se equivocó). \n",
    "* __answerChangedCount__: Es un contador de cuantas veces el niño cambió entre las opciones de respuesta antes de enviar la que él consideraba como correcta. El único lugar donde no está presente es en el colegio Hartfort, por lo que se optó por asignarlo como 1 para todos los niños de ese dataset. (Luego se justificará por qué).\n",
    "\n",
    "Se procede entonces a leer los datasets respectivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hartfortDf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-db5679754223>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mmarieDF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./datasets/firstModel/datos_marie_poussepin.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mmarieDF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmarieDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Unnamed: 0'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mhartfortDf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'hartfortDf' is not defined"
     ]
    }
   ],
   "source": [
    "#Reading the data\n",
    "hartfortDF = pd.read_csv('./datasets/firstModel/datos_hartfort.csv')\n",
    "hartfortDF = hartfortDF.drop(labels=['Unnamed: 0'],axis=1)\n",
    "ensenanzaDF = pd.read_csv('./datasets/firstModel/datos_la_ensenanza.csv');\n",
    "ensenanzaDF = ensenanzaDF.drop(labels=['Unnamed: 0'],axis=1)\n",
    "marcoDF = pd.read_csv('./datasets/firstModel/datos_marco_fidel.csv');\n",
    "marcoDF = marcoDF.drop(labels=['Unnamed: 0'],axis=1)\n",
    "sagradoDF = pd.read_csv('./datasets/firstModel/datos_sagrado.csv');\n",
    "sagradoDF = sagradoDF.drop(labels=['Unnamed: 0'],axis=1)\n",
    "marieDF = pd.read_csv('./datasets/firstModel/datos_marie_poussepin.csv');\n",
    "marieDF = marieDF.drop(labels=['Unnamed: 0'],axis=1)\n",
    "hartfortDf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardaremos ahora los dataframe de escuelas en 3 grupos principales: Público, Privado, General. Esto es para hacer un análisis de cada grupo y ver cómo se comportan nuestros datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edad</th>\n",
       "      <th>genero</th>\n",
       "      <th>grado</th>\n",
       "      <th>loID</th>\n",
       "      <th>tiempo</th>\n",
       "      <th>userID</th>\n",
       "      <th>isCorrect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3.846108</td>\n",
       "      <td>-LaQZtfxo0QA8Ij62dk1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.995306</td>\n",
       "      <td>-LaQZurPwCF55Hiv18kH</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.395411</td>\n",
       "      <td>-LaQZtfxo0QA8Ij62dk1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.422333</td>\n",
       "      <td>-LaQZurPwCF55Hiv18kH</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5.348062</td>\n",
       "      <td>-LaQZtfxo0QA8Ij62dk1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   edad  genero  grado  loID    tiempo                userID  isCorrect\n",
       "0    11       0      5     0  3.846108  -LaQZtfxo0QA8Ij62dk1          1\n",
       "1    10       0      5     0  2.995306  -LaQZurPwCF55Hiv18kH          1\n",
       "2    11       0      5     0  4.395411  -LaQZtfxo0QA8Ij62dk1          1\n",
       "3    10       0      5     0  2.422333  -LaQZurPwCF55Hiv18kH          1\n",
       "4    11       0      5     0  5.348062  -LaQZtfxo0QA8Ij62dk1          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schoolsDF = []\n",
    "publicSchools = []\n",
    "privateSchools = []\n",
    "schoolsDF.append(hartfortDF)\n",
    "schoolsDF.append(ensenanzaDF)\n",
    "schoolsDF.append(marcoDF)\n",
    "schoolsDF.append(sagradoDF)\n",
    "schoolsDF.append(marieDF)\n",
    "\n",
    "publicSchools.append(marcoDF)\n",
    "publicSchools.append(marieDF)\n",
    "privateSchools.append(hartfortDF)\n",
    "privateSchools.append(ensenanzaDF)\n",
    "privateSchools.append(sagradoDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que se hará entonces es agrupar los datos de cada niño. No nos interesa tanto saber cómo le fue en un ejercicio en específico, sino cómo le fue con todos los ejercicios del objetivo de aprendizaje. Hay que tener en cuenta que lo que se busca acá es un modelo general, entonces no se puede ir a cada ejercicio en particular, sino que queda mejor analizar por grupos de objetivos de aprendizaje. Entonces vamos a agrupar los datos de la siguiente forma:\n",
    "\n",
    "* __Grupo general__: Esto nos servirá para acceder a los datos más fácilmente, ya que el groupby permite acceder a los valores por indices, como si fuera una matríz. Para el fragmento de código de abajo, si ejecutamos generalGroupBy(data), lo que entrega es un dataframe y las columnas \"loID\" y \"grado\" serían los índices (i,j) que pueden ser accedidos solo con los valores de las posiciones (números). Si no se hiciera el groupby, debería necesariamente hacerse una consulta con expresión lambda para poder acceder a los datos.\n",
    "* __Grupo general por media de tiempo__: Lo mismo que el anterior, solo que ahora en vez de acceder a todos los otros datos por los que NO se agrupó, solo vamos a consderar el tiempo. Esto lo que retorna es el tiempo PROMEDIO que demoraron todos los niños de los diferentes grados, en los diferentes objetivos de aprendizaje.\n",
    "* __Grupo general por mediana de tiempo__: Misma lógica que el anterior, solo que ahora ya no es el PROMEDIO sino la MEDIA. Si se grafican los datos de los tiempos, se puede ver que la gráfica que resulta es una gráfica con sesgo. Por tanto, utilizar la media de los datos cuando estos presentan una distribución sesgada no es recomendable, ya resulta demasiado sensible a los datos aberrantes. Es mejor para casos así utilizar la mediana ( y es por esto que se utiliza esta función).\n",
    "\n",
    "Finalmente, reset_index() sirve para que los índices repetidos por el groupby se omitan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generalGroupBy(data):\n",
    "    return (data.groupby(['loID','grado']).mean())\n",
    "\n",
    "def generalGroupByTimeMEAN(data):\n",
    "    return (data.groupby(['loID','grado'])['tiempo'].mean())\n",
    "\n",
    "def generalGroupByTimeMEDIAN(data):\n",
    "    return (data.groupby(['loID','grado'])['tiempo'].median())\n",
    "\n",
    "###########################\n",
    "####### Analysis ##########\n",
    "schoolsMeansGB = []\n",
    "schoolsMediansGB = []\n",
    "schoolsGeneralGroupBy = []\n",
    "\n",
    "schoolsMeansGB.append(generalGroupByTimeMEAN(hartfortDF).reset_index())\n",
    "schoolsMeansGB.append(generalGroupByTimeMEAN(ensenanzaDF).reset_index())\n",
    "schoolsMeansGB.append(generalGroupByTimeMEAN(marcoDF).reset_index())\n",
    "schoolsMeansGB.append(generalGroupByTimeMEAN(sagradoDF).reset_index())\n",
    "schoolsMeansGB.append(generalGroupByTimeMEAN(marieDF).reset_index())\n",
    "\n",
    "schoolsMediansGB.append(generalGroupByTimeMEDIAN(hartfortDF).reset_index())\n",
    "schoolsMediansGB.append(generalGroupByTimeMEDIAN(ensenanzaDF).reset_index())\n",
    "schoolsMediansGB.append(generalGroupByTimeMEDIAN(marcoDF).reset_index())\n",
    "schoolsMediansGB.append(generalGroupByTimeMEDIAN(sagradoDF).reset_index())\n",
    "schoolsMediansGB.append(generalGroupByTimeMEDIAN(marieDF).reset_index())\n",
    "\n",
    "schoolsGeneralGroupBy.append(generalGroupBy(hartfortDF).reset_index())\n",
    "schoolsGeneralGroupBy.append(generalGroupBy(ensenanzaDF).reset_index())\n",
    "schoolsGeneralGroupBy.append(generalGroupBy(marcoDF).reset_index())\n",
    "schoolsGeneralGroupBy.append(generalGroupBy(sagradoDF).reset_index())\n",
    "schoolsGeneralGroupBy.append(generalGroupBy(marieDF).reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de variables ideales para el modelo\n",
    "\n",
    "Ahora que ya está listo el dataset, se busca encontrar variables que permitan ayudar a predecir la intensidad inicial de los ejercicios que se le colocará a un niño cuando entra por primera vez. \n",
    "\n",
    "Las variables con las que se cuenta son: **Edad**, **Género**, **Grado**, **Tiempo**, **Colegio**, **isCorrect**, **answerChangedCount**.\n",
    "\n",
    "Hay que tener en cuenta que lo que se busca es un modelo general. El objetivo es que el niño no se enfrente a algún pre-test o que conteste ejercicios para balancearlo por primera vez, sino lograr una estimación general dada la información de la que se dispone al momento de que ellos se unen al juego. Por tanto, no se puede incorporar al modelo las variables de titubeo (answerChangedCount), respuesta correcta ni tiempo.\n",
    "\n",
    "Lo que se hará ahora es realizar un análisis entre colegios para determinar si se presentan diferencias entre los colegios públicos y privados (Cosa que uno directamente se inclina a pensar y dice que sí la hay). Se procede pues, a separar los datos agrupados por colegios públicos y privados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "publicMeans = []\n",
    "privateMeans = []\n",
    "publicGeneral = []\n",
    "privateGeneral = []\n",
    "publicMeans.append(schoolsMeansGB[2])\n",
    "publicMeans.append(schoolsMeansGB[4])\n",
    "privateMeans.append(schoolsMeansGB[0])\n",
    "privateMeans.append(schoolsMeansGB[1])\n",
    "privateMeans.append(schoolsMeansGB[3])\n",
    "\n",
    "publicGeneral.append(schoolsGeneralGroupBy[2])\n",
    "publicGeneral.append(schoolsGeneralGroupBy[4])\n",
    "privateGeneral.append(schoolsGeneralGroupBy[0])\n",
    "privateGeneral.append(schoolsGeneralGroupBy[1])\n",
    "privateGeneral.append(schoolsGeneralGroupBy[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, lo que se hará es definir una función general que permita comparar entre colegios cómo le va a los niños de cada grado con respecto a otras variables como: Cantidad de veces que cambiaron entre opción de respuesta, cantidad de preguntas correctas y el tiempo (promedio) que tardaron en contestar los ejercicios de un objetivo de aprendizaje.\n",
    "\n",
    "dataComparison espera los siguientes parámetros:\n",
    "* __Schools__: Una lista de las escuelas.\n",
    "* __data__: El dataframe que se utilizará para sacar los datos (Medias, medianas, o alguno general)\n",
    "* __row__: Una de las variables (X) que se utilizará para comparar con respecto a otra (Y)\n",
    "* __col__: La segunda variable (Y) que está siendo comparada por la primera(X).\n",
    "* __figIndex__: El ID de la figura o plot a dibujar.\n",
    "* __Titulo__: El título de la gráfica.\n",
    "\n",
    "Entonces, lo que se está comparando en el siguiente bloque es:\n",
    "\n",
    "* __El promedio de tiempo que tardan los niños de cada grado__ en contestar los ejercicios de cada nivel de dificultad (Públicos).\n",
    "* __El promedio de preguntas correctas que contestan los niños de cada grado__ en cada nivel de dificultad (Públicos).\n",
    "* __El promedio de tiempo que tardan los niños de cada grado__ en contestar los ejercicios de cada nivel de dificultad (Privados).\n",
    "* __El promedio de preguntas correctas que contestan los niños de cada grado__ en cada nivel de dificultad (Privados).\n",
    "\n",
    "\n",
    "* __El PROMEDIO de tiempo que tardan los niños de cada grado__ en contestar los ejercicios de cada nivel de dificultad (Todos los colegios).\n",
    "* __La MEDIANA de tiempo que tardan los niños de cada grado__ en contestar los ejercicios de cada nivel de dificultad (Todos los colegios).\n",
    "* __El promedio de preguntas correctas que contestan los niños de cada grado__ en cada nivel de dificultad (Todos los colegios)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataComparison(schools,data,row,col,figIndex,titulo):\n",
    "    for i in range(1,6):\n",
    "        plt.figure(figIndex)\n",
    "        ax = plt.subplot(2,3,i)\n",
    "        for j in range(0,len(schools)):\n",
    "            plt.plot(data[j].loc[lambda x: x.loID == i-1][row],data[j].loc[lambda x: x.loID == i-1][col], label=schools[j]['escuela'][1])\n",
    "        \n",
    "        ax.set_xlabel('Grado', fontsize=12)\n",
    "        if(col=='isCorrect'):\n",
    "            plt.ylim(0,1)\n",
    "            ax.set_ylabel('% de correctas', fontsize=13)\n",
    "        elif(col=='answerChangedCount'):\n",
    "            plt.plot([1,2,3,4,5],[1,1,1,1,1], label='Ideal')\n",
    "            ax.set_ylabel('Promedio de selección', fontsize=13)\n",
    "            plt.ylim(0,2)\n",
    "        else:\n",
    "            ax.set_ylabel('Tiempo', fontsize=13)\n",
    "        if(i==5):\n",
    "            plt.suptitle(titulo)\n",
    "            plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "        plt.title(\"Objetivo de aprendizaje #\"+str(i), fontsize=13)\n",
    "        \n",
    "\n",
    "dataComparison(publicSchools, publicMeans,   'grado','tiempo',   24, 'Promedio de tiempos por colegio público')\n",
    "dataComparison(publicSchools, publicGeneral, 'grado','isCorrect',25, 'Porcentaje de respuestas correctas por colegio público')\n",
    "dataComparison(privateSchools,privateMeans,  'grado','tiempo',   26, 'Promedio de tiempos por colegio privado')\n",
    "dataComparison(privateSchools,privateGeneral,'grado','isCorrect',27, 'Porcentaje de respuestas correctas por colegio privado')\n",
    "\n",
    "#Time analysis MEAN\n",
    "dataComparison(schoolsDF,schoolsMeansGB, 'grado', 'tiempo', 1,'Promedio de tiempos por colegio ')\n",
    "#Time analysis MEDIAN (most accurate)\n",
    "dataComparison(schoolsDF,schoolsMediansGB, 'grado', 'tiempo', 2, 'Mediana de tiempos por colegio')\n",
    "#is Correct % analysis\n",
    "dataComparison(schoolsDF,schoolsGeneralGroupBy, 'grado', 'isCorrect', 3, 'Preguntas correctas por colegio')\n",
    "#changed Answers analysis\n",
    "#dataComparison(schoolsDF,schoolsGeneralGroupBy, 'grado', 'answerChangedCount', 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este análisis no muestra una diferencia significativa entre los colegios. Sí, puede verse que en algunos casos los niños de un mismo grado demoran más en algunos colegios que en otros, pero para decir que el colegio es un factor diferencial se esperaría que todos datos de análisis de los colegios públicos estuvieran separados de todos los colegios privados. Es decir, si se hubiera obtenido que los tiempos de ambos colegios privados siempre fueron mucho menores que todos los colegios públicos para un mismo grado, fuese fácil determinar que dicha variable es útil para encontrar patrones de datos. \n",
    "\n",
    "El género no se está mostrando en este análisis, pero modificando un poco la estructura de las funciones y llamados puede incorporarse para ver que el resultado será el mismo (porque ya se analizó previamente): No se puede ver una diferencia significativa entre los tiempos de los niños y niñas.\n",
    "\n",
    "De igual manera, se optó por utilizar estas variables a pesar de que los análsis indiquen que no aportarán mucho al modelo, pues se cuenta con ellas al momento de que un niño ingresa por primera vez y se tiene la esperanza de que a medida que el dataset crezca estas empiecen a cobrar más fuerza.\n",
    "\n",
    "### Estableciendo medidas de rendimiento\n",
    "\n",
    "Luego de preparar el dataset, se procederá a establecer medidas de rendimiento que ayudarán al modelo a predecir las intensidades de ejercicios para cada nivel de dificultad. Como se tienen 5 objetivos de aprendizaje, hay 5 niveles de intensidad asociados a cada uno. El mejor indicador de desempeño del jugador es el tiempo que tomó en realizar un ejercicio. Por tanto, se optó por crear una fórmula que traduzca su desempeño en un valor fijo para tener un indicio de qué tan bien está el niño. \n",
    "\n",
    "### Puntaje\n",
    "\n",
    "Para empezar, se definirá un puntaje base que disminuirá a medida que el jugador tome más tiempo para contestar la pregunta. Sin embargo, el tiempo que tarde en contestar será comparado directamente con la **mediana** del tiempo que tarden los niños que pertenezcan al mismo grado y colegio del jugador. Nuestra función entonces estará dada de la siguiente forma:\n",
    "\n",
    "\\begin{equation*}\n",
    "score = \\Bigr(20 - \\frac{tiempo}{3}\\Bigl) * isCorrect\n",
    "\\end{equation*}\n",
    "\n",
    "Siendo:\n",
    "* __tiempo__: El tiempo que tardó el jugador en contestar la pregunta.\n",
    "* __isCorrect__: Si la pregunta fue correcta (1) o incorrecta (0).\n",
    "\n",
    "Para evitar un puntaje negativo, tal que no se penalice al jugador muy fuerte, lo que se busca es que si se equivoca o tarda demasiado en resolver el ejercicio no se le otorgue puntaje. La primera versión de esta fórmula tenía establecido que si el jugador tardaba 60 segundos o más en contestar, el puntaje sería 0 (por esto el tiempo/3, para que cuando dure 60 segundos los puntos que le resten sean acordes al puntaje base de 20). Pero para que sea adaptativo a cada colegio, lo que se hizo fue establecer como frontera la mediana de tiempo por curso. Ahora, el tiempo límite que tendrá un niño para contestar el ejercicio estará definido por lo que hayan demorado los niños que pertenezcan a su mismo curso tras enfrentarse a un ejercicio del mismo nivel de dificultad.\n",
    "\n",
    "Por esto, el siguiente fragmento de código trabaja con las siguientes variables:\n",
    "* __answer['tiempo']__: Es el tiempo que tardó el niño en contestar el ejercicio.\n",
    "* __timesMedian[ answer['loID'] , answer['grado'] ]__: Es la mediana de tiempo para un objetivo de aprendizaje (nivel de dificultad) específico __loID__, de un grado cualquiera (1 a 5).\n",
    "* __timeLimit__: Para no hacerlo muy estricto, se otorgó arbitrariamente 2 segundos extra al tiempo. Así, para casos donde un niño tenga máxmimo 3 segundos de tiempo límite para contestar un ejercicio, ahora tendrá 5. (Esto se hizo pensando en la primera interacción con el juego, mientras se acostumbran a la dinámica)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def giveScoreToAnswer(answer, timesMedian):\n",
    "    time = answer['tiempo'];\n",
    "    timeLimit = int(timesMedian[answer['loID'],answer['grado']]) + 2;\n",
    "    if(time < timeLimit and answer['isCorrect'] == 1):\n",
    "        return 20-(time/3);\n",
    "    else:\n",
    "        return 0;\n",
    "\n",
    "#Adding score to each school\n",
    "hartfortDF['score'] = hartfortDF.apply(lambda x: giveScoreToAnswer(x, generalGroupByTimeMEDIAN(hartfortDF)), axis=1)\n",
    "ensenanzaDF['score'] = ensenanzaDF.apply(lambda x: giveScoreToAnswer(x, generalGroupByTimeMEDIAN(ensenanzaDF)), axis=1)\n",
    "marcoDF['score'] = marcoDF.apply(lambda x: giveScoreToAnswer(x, generalGroupByTimeMEDIAN(marcoDF)), axis=1)\n",
    "sagradoDF['score'] = sagradoDF.apply(lambda x: giveScoreToAnswer(x, generalGroupByTimeMEDIAN(sagradoDF)), axis=1)\n",
    "marieDF['score'] = marieDF.apply(lambda x: giveScoreToAnswer(x, generalGroupByTimeMEDIAN(marieDF)), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto, se tradujo el desempeño en cada ejercicio a un sistema de puntos. Saber cada ejercicio en específico no es el objetivo del modelo, así que se agrupará el desempeño del jugador por objetivos de aprendizaje, lo cual es posible por el ID de cada usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loID</th>\n",
       "      <th>grado</th>\n",
       "      <th>tiempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.064110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7.257710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.910470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.397869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.801245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.570393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4.913258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.818320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2.991299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2.406552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loID  grado     tiempo\n",
       "0     0      1  11.064110\n",
       "1     0      2   7.257710\n",
       "2     0      3   6.910470\n",
       "3     0      4   5.397869\n",
       "4     0      5   3.801245\n",
       "5     1      1   7.570393\n",
       "6     1      2   4.913258\n",
       "7     1      3   3.818320\n",
       "8     1      4   2.991299\n",
       "9     1      5   2.406552"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoresMeans = mergedDF.groupby(['userID','loID'])['score'].mean().reset_index();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora mismo se tiene el promedio de puntos de cada niño en cada objetivo de aprendizaje. Trabajar el modelo para que prediga el puntaje que tendrá en cada objetivo según sus datos de proveniencia (Colegio, grado) y variables explicativas (género, edad) es una forma de atacar el problema. Sin embargo, en vez de medir qué tan bien le va, se optó por estimar qué tantos ejercicios debe colocarle.\n",
    "\n",
    "Lo que se hace entonces es tranducir el puntaje de \"qué tan bien está\" en un \"qué tantos ejercicios se le deben colocar\" para dicho nivel de dificultad. Esto se logra de la siguiente forma:\n",
    "\n",
    "### Intensidad de los LO\n",
    "\n",
    "Lo que se hizo previamente fue tomar los puntajes obtenidos en los 5 ejercicios de cada objetivo de aprendizaje, sumarlos y dividirlos entre la cantidad de ejercicios. Partiendo de esto, si un niño contesta los 5 ejercicios perfectamente, su puntaje será o estará cerca de 20 (Máximo de puntos). \n",
    "\n",
    "Tomando su promedio de puntos y dividiéndolo entre el máximo de puntos posibles para obtener qué tan bien va, se obtiene un valor que considerado como **performance** para dicho objetivo de aprendizaje. La idea ahora es determinar una **intensidad** de ejercicios a presentar con base en dicho performance.  \n",
    "\n",
    "\\begin{eqnarray*}\n",
    "General Score = \\Bigl(\\frac{\\sum_{i=1}^{n}(Score_i)}{n}\\Bigr)\n",
    "\\\\\n",
    "Performance = \\frac{General Score}{20}\n",
    "\\end{eqnarray*}\n",
    "\n",
    "Donde\n",
    "* __n__: El número de ejercicios que realizó un jugador en un objetivo específico.\n",
    "* __Score__: Es el puntaje que obtuvo el jugador para ese ejercicio\n",
    "* __Score General__: El promedio de puntos entre los ejercicios resueltos.\n",
    "* __Performance__: Es qué tan bien le fue al jugador para en un objetivo específico. Está medido en escala de 0 a 1, siendo 0 muy mal y 1 muy bien.\n",
    "\n",
    "### Ejemplo\n",
    "\n",
    "Si un niño contesta de forma correcta y rápida 5 ejercicios de algún nivel de dificultad, se espera que obtenga los siguientes puntajes:\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "Puntajes = \\left(20,20,20,20,20\\right)\n",
    "\\end{eqnarray*}\n",
    "\n",
    "Por tanto, su score general sería el siguiente:\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "General Score = \\Bigl(\\frac{20+20+20+20+20}{5}\\Bigr)\n",
    "\\end{eqnarray*}\n",
    "\n",
    "Y por consiguiente, su performance:\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "Performance = \\frac{20}{20}\n",
    "\\end{eqnarray*}\n",
    "\n",
    "De este niño se puede interpretar que su performance en ese objetivo de aprendizaje es perfecto (1) y que no es necesario colocarle ejercicios. Lo que se puede hacer entonces es definir otra fórmula que a partir del performance determine la cantidad de ejercicios que se debe colocar. Se aprovechará que el performance da como resultado un porcentaje para establecer la siguiente fórmula:\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "LO Intensity = 1-performance\n",
    "\\end{eqnarray*}\n",
    "\n",
    "En síntesis, la intensidad se calcula como **lo que le falta al niño para llegar a un performance perfecto de 1** para un objetivo de aprendizaje cualquiera. Este cálculo parte del puntaje obtenido tras contestar un grupo de ejercicios correspondiente a cada objetivo de aprendizaje, y será utilizado fuertemente en el __modelo 2__. Por último, redondeamos este valor a 1 cifra significativa para que al momento de predecir no se tengan en cuenta tantos decimales y que el modelo empiece a llorar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edad</th>\n",
       "      <th>genero</th>\n",
       "      <th>grado</th>\n",
       "      <th>loID</th>\n",
       "      <th>tiempo</th>\n",
       "      <th>userID</th>\n",
       "      <th>isCorrect</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3.846108</td>\n",
       "      <td>-LaQZtfxo0QA8Ij62dk1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.717964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.995306</td>\n",
       "      <td>-LaQZurPwCF55Hiv18kH</td>\n",
       "      <td>1</td>\n",
       "      <td>19.001565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.395411</td>\n",
       "      <td>-LaQZtfxo0QA8Ij62dk1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.534863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.422333</td>\n",
       "      <td>-LaQZurPwCF55Hiv18kH</td>\n",
       "      <td>1</td>\n",
       "      <td>19.192556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5.348062</td>\n",
       "      <td>-LaQZtfxo0QA8Ij62dk1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   edad  genero  grado  loID    tiempo                userID  isCorrect  \\\n",
       "0    11       0      5     0  3.846108  -LaQZtfxo0QA8Ij62dk1          1   \n",
       "1    10       0      5     0  2.995306  -LaQZurPwCF55Hiv18kH          1   \n",
       "2    11       0      5     0  4.395411  -LaQZtfxo0QA8Ij62dk1          1   \n",
       "3    10       0      5     0  2.422333  -LaQZurPwCF55Hiv18kH          1   \n",
       "4    11       0      5     0  5.348062  -LaQZtfxo0QA8Ij62dk1          1   \n",
       "\n",
       "       score  \n",
       "0  18.717964  \n",
       "1  19.001565  \n",
       "2  18.534863  \n",
       "3  19.192556  \n",
       "4   0.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculateIntensities(userPerformance):\n",
    "    return (1-userPerformance.loc['score']/20);\n",
    "\n",
    "scoresMeans['intensity'] = scoresMeans.apply(calculateIntensities,axis=1);\n",
    "scoresMeans = scoresMeans.round({'intensity':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación del dataset\n",
    "\n",
    "Ya se tiene definidas las principales variables a trabajar, pero todavía hay que realizar algunos ajustes. Previamente se intentó traducir los colegios a dummy variables y enviar esto como dato de entrada, pero luego se optó por generalizar aún más ya que, a la larga, no sería bueno tener un arreglo muy absurdo de Dummy Variables de colegios si el dataset llegaba a incrementar. Lo que se hace es tomar la lista de colegios y categorizarlos entre públicos y privados, para así tener los datos partidos en 2 grandes grupos. Así, a la larga, servirá para en un futuro (si el dataset llega a crecer muchísimo) poder validar si efectivamente el colegio es o no una variable influyente en el modelo y poder dar una conclusión más precisa de si debe tenerse en cuenta o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>loID</th>\n",
       "      <th>score</th>\n",
       "      <th>intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-LaQZtfxo0QA8Ij62dk1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.329112</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-LaQZtfxo0QA8Ij62dk1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.341532</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-LaQZtfxo0QA8Ij62dk1</td>\n",
       "      <td>2</td>\n",
       "      <td>15.325926</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-LaQZtfxo0QA8Ij62dk1</td>\n",
       "      <td>3</td>\n",
       "      <td>18.892539</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-LaQZtfxo0QA8Ij62dk1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.845159</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-LaQZurPwCF55Hiv18kH</td>\n",
       "      <td>0</td>\n",
       "      <td>11.480608</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-LaQZurPwCF55Hiv18kH</td>\n",
       "      <td>1</td>\n",
       "      <td>15.371654</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-LaQZurPwCF55Hiv18kH</td>\n",
       "      <td>2</td>\n",
       "      <td>19.137623</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-LaQZurPwCF55Hiv18kH</td>\n",
       "      <td>3</td>\n",
       "      <td>18.635188</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-LaQZurPwCF55Hiv18kH</td>\n",
       "      <td>4</td>\n",
       "      <td>7.230178</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 userID  loID      score  intensity\n",
       "0  -LaQZtfxo0QA8Ij62dk1     0  11.329112        0.6\n",
       "1  -LaQZtfxo0QA8Ij62dk1     1  15.341532        0.8\n",
       "2  -LaQZtfxo0QA8Ij62dk1     2  15.325926        0.8\n",
       "3  -LaQZtfxo0QA8Ij62dk1     3  18.892539        0.9\n",
       "4  -LaQZtfxo0QA8Ij62dk1     4   3.845159        0.2\n",
       "5  -LaQZurPwCF55Hiv18kH     0  11.480608        0.6\n",
       "6  -LaQZurPwCF55Hiv18kH     1  15.371654        0.8\n",
       "7  -LaQZurPwCF55Hiv18kH     2  19.137623        1.0\n",
       "8  -LaQZurPwCF55Hiv18kH     3  18.635188        0.9\n",
       "9  -LaQZurPwCF55Hiv18kH     4   7.230178        0.4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convertSchool(user):\n",
    "    if(user['escuela']=='Hartford International School'):\n",
    "        return 0\n",
    "    elif(user['escuela'] == 'I.E.D. Marie Poussepin'):\n",
    "        return 3\n",
    "    elif(user['escuela'] == 'I.E.D Marco Fidel Suárez'):\n",
    "        return 4\n",
    "    elif(user['escuela'] == 'Colegio del Sagrado Corazón'):\n",
    "        return 1\n",
    "    else: \n",
    "        return 2\n",
    "    \n",
    "def isPublicOrPrivate(user):\n",
    "    if(user['escuela'] <= 2):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#General user information\n",
    "mergedDF['escuela'] = mergedDF.apply(convertSchool,axis=1)\n",
    "mergedDF['escuela'] = mergedDF.apply(isPublicOrPrivate,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Habiendo dejado lista la selección de variables de input, ahora se configurarán las variables de output. \n",
    "\n",
    "Como los datos permiten obtener una intensidad de cada niño para cada nivel de dificultad, se contará con un total de 5 intensidades. Este vector de 1x5 será agregado al dataframe actual, con la finalidad de analizar qué tan buena fue la selección de variables que se realizó para este primer modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edad</th>\n",
       "      <th>genero</th>\n",
       "      <th>grado</th>\n",
       "      <th>LOIN0</th>\n",
       "      <th>LOIN1</th>\n",
       "      <th>LOIN2</th>\n",
       "      <th>LOIN3</th>\n",
       "      <th>LOIN4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-LaQZtfxo0QA8Ij62dk1</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-LaQZurPwCF55Hiv18kH</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-LaQZvlOUvQcKzVILey9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-LaQZxvCZUvf9J0938NI</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-LaQ_08Mr96o00YYSj4_</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      edad  genero  grado  LOIN0  LOIN1  LOIN2  LOIN3  LOIN4\n",
       "userID                                                                      \n",
       "-LaQZtfxo0QA8Ij62dk1    11       0      5    0.6    0.8    0.8    0.9    0.2\n",
       "-LaQZurPwCF55Hiv18kH    10       0      5    0.6    0.8    1.0    0.9    0.4\n",
       "-LaQZvlOUvQcKzVILey9    10       0      5    0.8    1.0    0.6    0.8    0.2\n",
       "-LaQZxvCZUvf9J0938NI    10       0      5    0.9    1.0    0.8    0.9    0.5\n",
       "-LaQ_08Mr96o00YYSj4_    10       1      5    0.6    0.8    0.6    0.6    0.2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getIntensityDF(intensityDF):\n",
    "    LO0Array = []\n",
    "    LO1Array = []\n",
    "    LO2Array = []\n",
    "    LO3Array = []\n",
    "    LO4Array = []\n",
    "    IDArray = []\n",
    "    for i in range(0, len(scoresMeans), 5):\n",
    "        total = intensityDF.loc[i].intensity+intensityDF.loc[i+1].intensity+intensityDF.loc[i+2].intensity+intensityDF.loc[i+3].intensity+intensityDF.loc[i+4].intensity        \n",
    "        if(total == 0):\n",
    "            total = 1\n",
    "        IDArray.append(intensityDF.loc[i].userID)\n",
    "        LO0Array.append(intensityDF.loc[i].intensity/total)\n",
    "        LO1Array.append(intensityDF.loc[i+1].intensity/total)\n",
    "        LO2Array.append(intensityDF.loc[i+2].intensity/total)\n",
    "        LO3Array.append(intensityDF.loc[i+3].intensity/total)\n",
    "        LO4Array.append(intensityDF.loc[i+4].intensity/total)\n",
    "    d = {'userID':IDArray, 'LOI0': LO0Array,'LOI1': LO1Array,'LOI2': LO2Array,'LOI3': LO3Array,'LOI4': LO4Array}\n",
    "    return pd.DataFrame(data=d)\n",
    "\n",
    "generalUserInfo = mergedDF.groupby(['userID']).mean()\n",
    "generalUserInfo = generalUserInfo.drop(labels=['loID','tiempo','isCorrect','score'],axis=1);\n",
    "\n",
    "LOIntensitiesPerUser = getIntensityDF(scoresMeans);\n",
    "LOIntensitiesPerUser = LOIntensitiesPerUser.set_index('userID');\n",
    "LOIntensitiesPerUser = LOIntensitiesPerUser.round(2);\n",
    "generalUserInfo[['LOIN0','LOIN1','LOIN2','LOIN3','LOIN4']] = LOIntensitiesPerUser[['LOI0','LOI1','LOI2','LOI3','LOI4']];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede entonces a realizar un análsis de correlación con el método de Pearson, para ver qué tanto describen unas variables a otras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation analysis\n",
    "correlationData = generalUserInfo.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como era de esperarse, solo el grado y la edad tendrían una alta correlación entre sí. Los resultados obtenidos por el método van acorde a los análisis de gráficas realizados previamente, donde se pudo ver que las demás variables no tenían mucha influencia en el desempeño del jugador. Al final de todo se encuentra un apartado dedicado a las mejoras que se pensaron para abordar este problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construcción de la Red Neuronal\n",
    "\n",
    "Luego de que se tiene el dataset listo, se procede a partir entre variables independientes e independientes. Este proceso es para pasar los datos a la red neuronal.\n",
    "\n",
    "\n",
    "### Arquitectura\n",
    "\n",
    "El primer modelo de red neuronal que se diseñará se encargará de nivelar a un nuevo jugador. Cuando un nuevo jugador ingrese, la red deberá estimar las intensidades de los niveles de aprendizaje con base en el **colegio** (público o privado), **edad**, **género** y **grado**.\n",
    "\n",
    "<img height=600, width=600, src=\"NeuralNetArch.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset\n",
    "#Let X be Edad,Grado and Genero\n",
    "X = generalUserInfo.drop(labels=['LOIN0','LOIN1','LOIN2','LOIN3','LOIN4'],axis=1);\n",
    "#Let Y be the 5 intensities\n",
    "Y = generalUserInfo[['LOIN0','LOIN1','LOIN2','LOIN3','LOIN4']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utilizará el 80% de los datos para entrenamiento y 20% para probar. Además, se deben escalar los datos para evitar la dominancia entre variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Steven\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:617: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Steven\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\Steven\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=101)\n",
    "sc = StandardScaler() #Must be scaled to avoid variable domination\n",
    "\n",
    "#pickle.dumps(X.describe(),'normalizingData')\n",
    "#X = preprocessing.normalize(X,axis=1)\n",
    "trainedScaler = sc.fit(X_train);\n",
    "#joblib.dump(sc, 'scaler.joblib');\n",
    "\n",
    "#Transforming dataset\n",
    "X_train = trainedScaler.transform(X_train)\n",
    "X_test = trainedScaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción de la red\n",
    "\n",
    "Utilizando la librería de Keras, se definirá la red neuronal como una secuencia de capas. Siguiendo el gráfico explicado en la sección anterior, tendrémos 3 capas: \n",
    "\n",
    "#### Input Layer\n",
    "Recibirá los datos de entrada: Tipo de colegio, Edad, Género y Grado. Por tanto, la dimensión de esta capa debe ser 4.\n",
    "\n",
    "#### Hidden Layer\n",
    "Recibirá los datos de entrada y realizará diferentes combinaciones entre ellos buscandor relaciones para obtener las intensidades. Se utilizará la funcion de activcación de _Rectifier Linear Unit(ReLU)_ porque tradicionalmente es la que mejor performance da y hace que la red sea más fácil y rápido de entrenar a la red neuronal. Entre otras ventajas que presenta sobre otras funciones (sigmoide y tanh) es que esta no es tan sensible a los cambios. La cantidad de nodos que se llevará esta red es de 5. Como no hay una respuesta precisa de cuántas unidades se deben usar, se probaron diferentes cantidades de neuronas (3 a 10, 15, 20) se eligió la configuración que mejores resultados dió.\n",
    "\n",
    "#### Output Layer\n",
    "Contará con los 5 outputs respectivos a la intensidad de cada nivel de dificultad.\n",
    "\n",
    "#### Kernel Initializers\n",
    "Son las distribuciones con las que se asignarán los pesos a las aristas de la red neuronal. Entre distribución uniforme y normal no hay mucha diferencia en cuanto a qué tanto influyen en el modelo, pues ambos dan buenos resultados. Tomamos entonces una inicialización normal para las aristas de la hidden layer y una uniforme para la output layer.\n",
    "\n",
    "#### Optimizer\n",
    "Es la función para encontrar los valores óptimos. Como estamos haciendo una regresión, utilizamos el Stochastic Gradient Descent (SGD) ya que es mejor para aproximaciones.\n",
    "\n",
    "#### Loss\n",
    "La función de optimización de los pesos usaremos el error cuadrático medio (MSE). Esto principalmente por ser una regresión y porque se buscan valores que sean lo más cercanos posible.\n",
    "\n",
    "#### Metrics\n",
    "Para medir la precisión del modelo se utilziarán el MSE y el error absoluto medio (MAE).\n",
    "\n",
    "### Entrenamiento de la red\n",
    "\n",
    "#### batch_size\n",
    "La cantidad de muestras que tomará la red para entrenarse al momento de hacer una propagación (paso entre input - hidden - output) para luego re calcular los pesos y ajustarse. Lo ideal es que no sea muy pequeño para que el movimiento del gradiente pueda dar resultados más precisos, pero tampoco muy grande para que no consuma mucha memoria. Se realizaron varias pruebas con cantidades variables de batch, pero no se obtuvieron resultados significativos cuando se optaba por usarlo o no. La versión final de la red trabaja sin batch pero, si se busca mejorar la arquitectura, no está de más probar con diferentes tamaños de batch para tratar de obtener mejores resultados.\n",
    "\n",
    "#### epochs\n",
    "La cantidad de veces que repetirá todo el proceso de entrenamiento con el dataset. 1 época se define como una pasada completa de todo el dataset, tras haber hecho proceso de forward y backward propagation.\n",
    "\n",
    "Entonces para nuestra red que consta de 620 ejemplares para entrenar, analizarán todos de golpe para calcular los pesos. Al terminar, habrá finalizado una época. Entonces vuelve a repetirse 49 épocas más para mejorar su precisión.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "92/92 [==============================] - 19s 204ms/step - loss: 0.2664 - mean_squared_error: 0.2664 - mean_absolute_error: 0.4224\n",
      "Epoch 2/50\n",
      "92/92 [==============================] - 0s 602us/step - loss: 0.2392 - mean_squared_error: 0.2392 - mean_absolute_error: 0.4000\n",
      "Epoch 3/50\n",
      "92/92 [==============================] - 0s 596us/step - loss: 0.2160 - mean_squared_error: 0.2160 - mean_absolute_error: 0.3792\n",
      "Epoch 4/50\n",
      "92/92 [==============================] - 0s 618us/step - loss: 0.1957 - mean_squared_error: 0.1957 - mean_absolute_error: 0.3598\n",
      "Epoch 5/50\n",
      "92/92 [==============================] - 0s 791us/step - loss: 0.1787 - mean_squared_error: 0.1787 - mean_absolute_error: 0.3422\n",
      "Epoch 6/50\n",
      "92/92 [==============================] - 0s 640us/step - loss: 0.1637 - mean_squared_error: 0.1637 - mean_absolute_error: 0.3257\n",
      "Epoch 7/50\n",
      "92/92 [==============================] - 0s 737us/step - loss: 0.1510 - mean_squared_error: 0.1510 - mean_absolute_error: 0.3128\n",
      "Epoch 8/50\n",
      "92/92 [==============================] - 0s 705us/step - loss: 0.1402 - mean_squared_error: 0.1402 - mean_absolute_error: 0.3021\n",
      "Epoch 9/50\n",
      "92/92 [==============================] - 0s 694us/step - loss: 0.1308 - mean_squared_error: 0.1308 - mean_absolute_error: 0.2927\n",
      "Epoch 10/50\n",
      "92/92 [==============================] - 0s 672us/step - loss: 0.1231 - mean_squared_error: 0.1231 - mean_absolute_error: 0.2852\n",
      "Epoch 11/50\n",
      "92/92 [==============================] - 0s 683us/step - loss: 0.1161 - mean_squared_error: 0.1161 - mean_absolute_error: 0.2783\n",
      "Epoch 12/50\n",
      "92/92 [==============================] - 0s 542us/step - loss: 0.1101 - mean_squared_error: 0.1101 - mean_absolute_error: 0.2725\n",
      "Epoch 13/50\n",
      "92/92 [==============================] - 0s 683us/step - loss: 0.1050 - mean_squared_error: 0.1050 - mean_absolute_error: 0.2670\n",
      "Epoch 14/50\n",
      "92/92 [==============================] - 0s 791us/step - loss: 0.1007 - mean_squared_error: 0.1007 - mean_absolute_error: 0.2624\n",
      "Epoch 15/50\n",
      "92/92 [==============================] - 0s 813us/step - loss: 0.0971 - mean_squared_error: 0.0971 - mean_absolute_error: 0.2583\n",
      "Epoch 16/50\n",
      "92/92 [==============================] - 0s 867us/step - loss: 0.0937 - mean_squared_error: 0.0937 - mean_absolute_error: 0.2543\n",
      "Epoch 17/50\n",
      "92/92 [==============================] - 0s 650us/step - loss: 0.0909 - mean_squared_error: 0.0909 - mean_absolute_error: 0.2510\n",
      "Epoch 18/50\n",
      "92/92 [==============================] - 0s 715us/step - loss: 0.0887 - mean_squared_error: 0.0887 - mean_absolute_error: 0.2482\n",
      "Epoch 19/50\n",
      "92/92 [==============================] - 0s 954us/step - loss: 0.0867 - mean_squared_error: 0.0867 - mean_absolute_error: 0.2456\n",
      "Epoch 20/50\n",
      "92/92 [==============================] - 0s 856us/step - loss: 0.0850 - mean_squared_error: 0.0850 - mean_absolute_error: 0.2435\n",
      "Epoch 21/50\n",
      "92/92 [==============================] - 0s 575us/step - loss: 0.0834 - mean_squared_error: 0.0834 - mean_absolute_error: 0.2415\n",
      "Epoch 22/50\n",
      "92/92 [==============================] - 0s 642us/step - loss: 0.0820 - mean_squared_error: 0.0820 - mean_absolute_error: 0.2397\n",
      "Epoch 23/50\n",
      "92/92 [==============================] - 0s 672us/step - loss: 0.0810 - mean_squared_error: 0.0810 - mean_absolute_error: 0.2383\n",
      "Epoch 24/50\n",
      "92/92 [==============================] - 0s 705us/step - loss: 0.0799 - mean_squared_error: 0.0799 - mean_absolute_error: 0.2369\n",
      "Epoch 25/50\n",
      "92/92 [==============================] - 0s 667us/step - loss: 0.0792 - mean_squared_error: 0.0792 - mean_absolute_error: 0.2357\n",
      "Epoch 26/50\n",
      "92/92 [==============================] - 0s 737us/step - loss: 0.0785 - mean_squared_error: 0.0785 - mean_absolute_error: 0.2346\n",
      "Epoch 27/50\n",
      "92/92 [==============================] - 0s 689us/step - loss: 0.0778 - mean_squared_error: 0.0778 - mean_absolute_error: 0.2334\n",
      "Epoch 28/50\n",
      "92/92 [==============================] - 0s 726us/step - loss: 0.0773 - mean_squared_error: 0.0773 - mean_absolute_error: 0.2324\n",
      "Epoch 29/50\n",
      "92/92 [==============================] - 0s 575us/step - loss: 0.0768 - mean_squared_error: 0.0768 - mean_absolute_error: 0.2315\n",
      "Epoch 30/50\n",
      "92/92 [==============================] - 0s 650us/step - loss: 0.0764 - mean_squared_error: 0.0764 - mean_absolute_error: 0.2308\n",
      "Epoch 31/50\n",
      "92/92 [==============================] - 0s 672us/step - loss: 0.0760 - mean_squared_error: 0.0760 - mean_absolute_error: 0.2301\n",
      "Epoch 32/50\n",
      "92/92 [==============================] - 0s 694us/step - loss: 0.0756 - mean_squared_error: 0.0756 - mean_absolute_error: 0.2292\n",
      "Epoch 33/50\n",
      "92/92 [==============================] - 0s 726us/step - loss: 0.0753 - mean_squared_error: 0.0753 - mean_absolute_error: 0.2287\n",
      "Epoch 34/50\n",
      "92/92 [==============================] - 0s 770us/step - loss: 0.0749 - mean_squared_error: 0.0749 - mean_absolute_error: 0.2280\n",
      "Epoch 35/50\n",
      "92/92 [==============================] - 0s 629us/step - loss: 0.0747 - mean_squared_error: 0.0747 - mean_absolute_error: 0.2276\n",
      "Epoch 36/50\n",
      "92/92 [==============================] - 0s 607us/step - loss: 0.0745 - mean_squared_error: 0.0745 - mean_absolute_error: 0.2271\n",
      "Epoch 37/50\n",
      "92/92 [==============================] - 0s 564us/step - loss: 0.0743 - mean_squared_error: 0.0743 - mean_absolute_error: 0.2267\n",
      "Epoch 38/50\n",
      "92/92 [==============================] - 0s 629us/step - loss: 0.0741 - mean_squared_error: 0.0741 - mean_absolute_error: 0.2262\n",
      "Epoch 39/50\n",
      "92/92 [==============================] - 0s 510us/step - loss: 0.0739 - mean_squared_error: 0.0739 - mean_absolute_error: 0.2259\n",
      "Epoch 40/50\n",
      "92/92 [==============================] - 0s 521us/step - loss: 0.0737 - mean_squared_error: 0.0737 - mean_absolute_error: 0.2256\n",
      "Epoch 41/50\n",
      "92/92 [==============================] - 0s 531us/step - loss: 0.0736 - mean_squared_error: 0.0736 - mean_absolute_error: 0.2252\n",
      "Epoch 42/50\n",
      "92/92 [==============================] - 0s 596us/step - loss: 0.0734 - mean_squared_error: 0.0734 - mean_absolute_error: 0.2249\n",
      "Epoch 43/50\n",
      "92/92 [==============================] - 0s 531us/step - loss: 0.0733 - mean_squared_error: 0.0733 - mean_absolute_error: 0.2246\n",
      "Epoch 44/50\n",
      "92/92 [==============================] - 0s 683us/step - loss: 0.0732 - mean_squared_error: 0.0732 - mean_absolute_error: 0.2244\n",
      "Epoch 45/50\n",
      "92/92 [==============================] - 0s 553us/step - loss: 0.0731 - mean_squared_error: 0.0731 - mean_absolute_error: 0.2241\n",
      "Epoch 46/50\n",
      "92/92 [==============================] - 0s 542us/step - loss: 0.0730 - mean_squared_error: 0.0730 - mean_absolute_error: 0.2240\n",
      "Epoch 47/50\n",
      "92/92 [==============================] - 0s 564us/step - loss: 0.0729 - mean_squared_error: 0.0729 - mean_absolute_error: 0.2237\n",
      "Epoch 48/50\n",
      "92/92 [==============================] - 0s 477us/step - loss: 0.0727 - mean_squared_error: 0.0727 - mean_absolute_error: 0.2235\n",
      "Epoch 49/50\n",
      "92/92 [==============================] - 0s 542us/step - loss: 0.0726 - mean_squared_error: 0.0726 - mean_absolute_error: 0.2232\n",
      "Epoch 50/50\n",
      "92/92 [==============================] - 0s 537us/step - loss: 0.0725 - mean_squared_error: 0.0725 - mean_absolute_error: 0.2230\n"
     ]
    }
   ],
   "source": [
    "#Building the ANN\n",
    "classifier = Sequential();\n",
    "classifier.add(Dense(input_dim=4, activation='relu', kernel_initializer='normal', units=5));\n",
    "classifier.add(Dense(kernel_initializer='uniform',units=5))\n",
    "classifier.compile(optimizer='sgd', loss='mean_squared_error', metrics=['mse','mae']);\n",
    "modelHistory = classifier.fit(X_train, y_train, epochs=50)\n",
    "\n",
    "y_pred = classifier.predict(X_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, esta configuración con la red neuronal que otorga un error de 0,0701 se guarda en un archivo. Este contendrá los pesos y toda la arquitectura que definimos para el funcionamiento de sus capas, tal que cuando se vuelva a utilizar solo sea cargar la información y no haya que volver a entrenar el modelo. De la misma forma, el StandardScaler utilizado para normalizar los datos de entrada fue guardado en un archivo .joblib para ser cargado.\n",
    "\n",
    "Se finaliza entonces con una gráfica que contrasta los resultados obtenidos por la red neuronal con los datos reales. En ella se evidencia que el modelo realiza una regresión con base en la media, debido a que no cuenta con las suficientes variables explicativas para ajustarse a cada caso en particular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictionsAnalysis(testValues, predictions, size):\n",
    "    LO0 = []\n",
    "    LO1 = []\n",
    "    LO2 = []\n",
    "    LO3 = []\n",
    "    LO4 = []\n",
    "    for i in range(0,size):\n",
    "        LO0.append(predictions[i][0])\n",
    "        LO1.append(predictions[i][1])\n",
    "        LO2.append(predictions[i][2])\n",
    "        LO3.append(predictions[i][3])\n",
    "        LO4.append(predictions[i][4])\n",
    "    \n",
    "    for i in range(1,6):\n",
    "        plt.figure(5)\n",
    "        ax = plt.subplot(2,3,i)\n",
    "        if(i == 1):\n",
    "            testArray = testValues['LOIN0']\n",
    "            LO = LO0;\n",
    "        elif(i == 2):\n",
    "            testArray = testValues['LOIN1']\n",
    "            LO = LO1;\n",
    "        elif(i == 3):\n",
    "            testArray = testValues['LOIN2']\n",
    "            LO = LO2;\n",
    "        elif(i == 4):\n",
    "            testArray = testValues['LOIN3']\n",
    "            LO = LO3;\n",
    "        else:\n",
    "            testArray = testValues['LOIN4']\n",
    "            LO = LO4;\n",
    "            \n",
    "        plt.scatter(list(range(0,size)),testArray)\n",
    "        plt.scatter(list(range(0,size)),LO)\n",
    "        plt.plot(list(range(0,size)),testArray,label='Valor Real')\n",
    "        plt.plot(list(range(0,size)),LO,label='Predicción')\n",
    "        ax.set_xlabel('Observación',fontsize=13)\n",
    "        ax.set_ylabel('Intensidad',fontsize=13)\n",
    "        plt.ylim(0,1)\n",
    "        plt.title('Objetivo de aprendizaje #'+str(i))\n",
    "        if(i == 5):\n",
    "            plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "            plt.suptitle('Comparación entre valor real y la predicción del modelo')\n",
    "\n",
    "predictionsAnalysis(y_test, y_pred, len(y_pred))\n",
    "#classifier.save('NewPlayerNeuralNet.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aspectos a mejorar\n",
    "\n",
    "Entre las posibles alternativas que se pensaron para mejorar el modelo están las siguientes:\n",
    "* __Inclusión de variables demográficas__: Posiblemente, contar con más variables que permitan tener información previa del niño permita encontrar algo que justifique su desempeño en cada nivel de dificultad.\n",
    "* __Incluir información académica__: Posiblemente, incorporar otros datos como sus notas y rendimiento en el colegio permita que el modelo justifique su desempeño en cada nivel de dificultad.\n",
    "* __Recolectar más datos provenientes de más colegios__: Es evidente que entre más datos hayan mejor se podrá entrenar cualquier modelo y puede que más particularidades puedan encontrarse. Siempre es recomendable levantar más datos, sobretodo porque para este proyecto no se contaba con algo como datos abiertos ni nada, sino que el dataset debió de crearse y a medida que se visitaban otros colegios se iban incorporando unas que otras variables.\n",
    "* __Replantear la estrucutra del dataset__: Va de la mano con las 2 primeras sugerencias. Posiblemente si piensan en otra estructura para levantamiento de datos y así estudiarlos puede que esto conlleve a que se pueda formular un modelo más poderoso y preciso.\n",
    "* __Aplicar las sugerencias de arquitectura__: Diferentes pruebas con otros optimizadores, tamaños de batch, epochs, inicializadores de pesos para las neuronas y diferentes random state de inicio"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
